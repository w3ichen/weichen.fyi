(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[6078],{69553:function(e,t,r){Promise.resolve().then(r.bind(r,95551))},95656:function(e,t,r){"use strict";r.d(t,{Z:function(){return l}});var n=r(98636),i=r(56063),a=r(99163),o=r(22166);let s=(0,r(94143).Z)("MuiBox",["root"]),c=(0,a.Z)();var l=(0,n.default)({themeId:o.Z,defaultTheme:c,defaultClassName:s.root,generateClassName:i.Z.generate})},98636:function(e,t,r){"use strict";r.d(t,{default:function(){return u}});var n=r(2265),i=r(61994),a=r(68241),o=r(38720),s=r(95086),c=r(20135),l=r(57437);function u(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{themeId:t,defaultTheme:r,defaultClassName:u="MuiBox-root",generateClassName:d}=e,h=(0,a.ZP)("div",{shouldForwardProp:e=>"theme"!==e&&"sx"!==e&&"as"!==e})(o.Z);return n.forwardRef(function(e,n){let a=(0,c.default)(r),{className:o,component:p="div",...f}=(0,s.Z)(e);return(0,l.jsx)(h,{as:p,ref:n,className:(0,i.Z)(o,d?d(u):u),theme:t&&a[t]||a,...f})})}},95551:function(e,t,r){"use strict";r.r(t),r.d(t,{default:function(){return p}});var n=r(57437),i=r(70264),a=r(80880),o=r(18311),s=r(8958),c=r(53874),l=r(16210),u=r(85765),d=r(46387);let h=(0,l.default)(u.Z)(e=>{let{}=e;return{}});function p(){return(0,n.jsxs)(h,{maxWidth:"md",children:[(0,n.jsx)(c.Z,{title:"Huawei Canada",imgSrc:"swe/huawei_logo2.png"}),(0,n.jsx)(o.M,{src:"swe/huawei_hero.jpg",sx:{height:"300px"}}),(0,n.jsx)(s.Z,{skills:["AI","Research","CS","Computer Vision","Graph Neural Networks","Deep Learning","Machine Learning","Neural Architecture Search","Python","PyTorch","PyTorch Geometric","Linux","NVIDIA CUDA","Anaconda","Draw.io","Git","Overleaf","Markdown"],buttons:[{url:"https://www.huawei.com/ca",text:"huawei.com/ca",type:"web"},{url:"https://arxiv.org/abs/2501.00636",text:"DAC23 Paper",type:"paper"},{url:"https://arxiv.org/abs/2211.17228",text:"AAAI23 Paper",type:"paper"}]}),(0,n.jsx)(a.ZP,{src:"swe/huawei_xmas.jpg",title:"Neural Architecture Search Team",caption:"I conducted cutting-edge AI research using PyTorch, running experiments on NVIDIA GPUs in a Linux environment. This involved performing literature reviews, translating high-level concepts into code, implementing algorithms from research papers, and visualizing results with Matplotlib. Collaboration with a Ph.D. student resulted in the publication of two AI papers.",mt:2}),(0,n.jsx)(d.Z,{variant:"h5",pt:6,gutterBottom:!0,children:"AIO-P: Expanding Neural Performance Predictors Beyond Image Classification"}),(0,n.jsxs)(d.Z,{variant:"body1",children:["Keith G. Mills, Di Niu, Mohammad Salameh, ",(0,n.jsx)("strong",{children:"Weichen Qiu"}),", Fred X. Han, Puyuan Liu, Jialin Zhang, Wei Lu, Shangling Jui. “AIO-P: Expanding Neural Performance Predictors Beyond Image Classification.” The 37th Association for the Advancement of Artificial Intelligence Conference. Feb. 2023."," ",(0,n.jsx)(i.Z,{href:"https://arxiv.org/abs/2211.17228",children:"[Arxiv]"})]}),(0,n.jsx)(d.Z,{variant:"caption",children:"Accepted as a full paper at AAAI 2023, 19.6% acceptance rate."}),(0,n.jsx)(d.Z,{variant:"subtitle1",mt:1,children:"ABSTRACT"}),(0,n.jsx)(d.Z,{variant:"body2",children:"Evaluating neural network performance is critical to deep neural network design but a costly procedure. Neural predictors provide an efficient solution by treating architectures as samples and learning to estimate their performance on a given task. However, existing predictors are task-dependent, predominantly estimating neural network performance on image classification benchmarks. They are also search-space dependent; each predictor is designed to make predictions for a specific architecture search space with predefined topologies and set of operations. In this paper, we propose a novel All-in-One Predictor (AIO-P), which aims to pretrain neural predictors on architecture examples from multiple, separate computer vision (CV) task domains and multiple architecture spaces, and then transfer to unseen downstream CV tasks or neural architectures. We describe our proposed techniques for general graph representation, efficient predictor pretraining and knowledge infusion techniques, as well as methods to transfer to downstream tasks/spaces. Extensive experimental results show that AIO-P can achieve Mean Absolute Error (MAE) and Spearman's Rank Correlation (SRCC) below 1% and above 0.5, respectively, on a breadth of target downstream CV tasks with or without fine-tuning, outperforming a number of baselines. Moreover, AIO-P can directly transfer to new architectures not seen during training, accurately rank them and serve as an effective performance estimator when paired with an algorithm designed to preserve performance while reducing FLOPs."}),(0,n.jsx)(a.ZP,{src:"swe/huawei_aiop_fig3.jpg",title:" CG K-Adapter Diagram",caption:"Fig 3 in paper: We start with a graph encoder pre-trained on NAS-Bench-101 for IC and further extend the design with an adapter. The original encoder is frozen while we train the K-Adapter on a new search space and task, e.g., R50 on OD.",mt:4}),(0,n.jsx)(d.Z,{variant:"h5",pt:6,gutterBottom:!0,children:"Applying Graph Explanation to Operator Fusion"}),(0,n.jsxs)(d.Z,{variant:"body1",children:["Keith G. Mills, Muhammad Fetrat Qharabagh, ",(0,n.jsx)("strong",{children:"Weichen Qiu"}),", Fred X. Han, Mohammad Salameh, Wei Lu, Shangling Jui, Di Niu. “Applying Graph Explanation to Operator Fusion.” The 60th Design Automation Conference (DAC 2023). July 2023."," ",(0,n.jsx)(i.Z,{href:"https://arxiv.org/abs/2501.00636",children:"[Arxiv]"})," ",(0,n.jsx)(i.Z,{href:"https://kgmills.github.io/assets/posters/applying_get_op_fusion_DAC2023.pdf",children:"[Poster]"})," ",(0,n.jsx)(i.Z,{href:"https://60dac.conference-program.com/presentation/?id=RESEARCH145&sess=sess243",children:"[DAC Session]"})]}),(0,n.jsx)(d.Z,{variant:"caption",children:"Accepted as a WIP poster at DAC 2023."}),(0,n.jsx)(d.Z,{variant:"subtitle1",mt:1,children:"ABSTRACT"}),(0,n.jsx)(d.Z,{variant:"body2",children:"Layer fusion techniques are critical to improving the inference efficiency of deep neural networks (DNN) for deployment. Fusion aims to lower inference costs by reducing data transactions between an accelerator's on-chip buffer and DRAM. This is accomplished by grouped execution of multiple operations like convolution and activations together into single execution units - fusion groups. However, on-chip buffer capacity limits fusion group size and optimizing fusion on whole DNNs requires partitioning into multiple fusion groups. Finding the optimal groups is a complex problem where the presence of invalid solutions hampers traditional search algorithms and demands robust approaches. In this paper we incorporate Explainable AI, specifically Graph Explanation Techniques (GET), into layer fusion. Given an invalid fusion group, we identify the operations most responsible for group invalidity, then use this knowledge to recursively split the original fusion group via a greedy tree-based algorithm to minimize DRAM access. We pair our scheme with common algorithms and optimize DNNs on two types of layer fusion: Line-Buffer Depth First (LBDF) and Branch Requirement Reduction (BRR). Experiments demonstrate the efficacy of our scheme on several popular and classical convolutional neural networks like ResNets and MobileNets. Our scheme achieves over 20% DRAM Access reduction on EfficientNet-B3."}),(0,n.jsx)(a.ZP,{src:"swe/huawei_dac_fig1.jpg",title:"Line-Buffer Depth First (LBDF)",caption:"Fig 1 in paper: LBDF on a fusion group consisting of two 3 x 3 convolution kernels in sequence. Area bounded by the red square denotes the input data required to compute the current output. '-' denotes the next data entries to be released from the on-chip buffer. '+' denotes the next data point to be loaded from DRAM (input map) or computed (intermediate map).",mt:4}),(0,n.jsx)(a.ZP,{src:"swe/huawei_dac_fig2.jpg",title:"High-Level Overview of Scheme",caption:"Fig 2 in paper: (a): A search algorithm generates a partition plan, and an analytical validity checker determines the feasibility of each fusion group in the plan. (b): We use a GNN and GETs to find a subgraph explanation for each invalid fusion group. (c): We consider how to split the fusion group at every solution edge contained within the subgraph explanation. Note how the explanation contains a skip-connection, meaning we must cut at least 2 edges. (d): We use a greedy tree-based algorithm to consider all possible solutions which split the fusion group and sort them based whether the number of new fusion groups. In the optimal case (green arrow), both new fusion groups are valid. If one (blue arrow) or both (red arrow) of the fusion groups are invalid, we use the recursive algorithm to repeat the process from step (a) for each invalid fusion group.",direction:"column",spacing:1,mt:4}),(0,n.jsx)(d.Z,{variant:"h5",pt:6,gutterBottom:!0,children:"Certifications"}),(0,n.jsxs)("ul",{children:[(0,n.jsxs)("li",{style:{marginLeft:"20px"},children:["Deep Learning Specialization by Andrew Ng at DeepLearning.AI"," ",(0,n.jsx)(i.Z,{href:"https://www.coursera.org/specializations/deep-learning",children:"[Coursera]"})]}),(0,n.jsxs)("li",{style:{marginLeft:"50px"},children:["Convolutional Neural Networks Issued May 2022"," ",(0,n.jsx)(i.Z,{href:"https://www.coursera.org/account/accomplishments/certificate/7HD6GGCW34FQ",children:"[Credential ID: 7HD6GGCW34FQ]"})]}),(0,n.jsxs)("li",{style:{marginLeft:"50px"},children:["Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization Issued May 2022"," ",(0,n.jsx)(i.Z,{href:"https://www.coursera.org/account/accomplishments/certificate/9M7BVQ5FVXZF",children:"[Credential ID: 9M7BVQ5FVXZF]"})]}),(0,n.jsxs)("li",{style:{marginLeft:"50px"},children:["Neural Networks and Deep Learning Issued May 2022"," ",(0,n.jsx)(i.Z,{href:"https://www.coursera.org/account/accomplishments/certificate/AYAE7NPQYQMC",children:"[Credential ID: AYAE7NPQYQMC]"})]}),(0,n.jsxs)("li",{style:{marginLeft:"50px"},children:["Structuring Machine Learning Projects Issued May 2022"," ",(0,n.jsx)(i.Z,{href:"https://www.coursera.org/account/accomplishments/certificate/ZZSRMGAATUPC",children:"[Credential ID: ZZSRMGAATUPC]"})]})]})]})}},70264:function(e,t,r){"use strict";r.d(t,{Z:function(){return a}});var n=r(57437),i=r(27648);function a(e){let{href:t,children:r,...a}=e;return(0,n.jsx)(i.default,{href:t,target:"_blank",rel:"noopener noreferrer",...a,children:r})}},53527:function(e,t,r){"use strict";r.d(t,{Z:function(){return d}});var n=r(57437),i=r(16210),a=r(95656),o=r(41530),s=r(46387),c=r(70264);let l=(0,i.default)("div")({display:"flex",flex:2}),u=(0,i.default)(a.Z)(e=>{let{theme:t}=e;return{display:"flex",flex:1,flexDirection:"column",justifyContent:"center",padding:0,[t.breakpoints.down("md")]:{textAlign:"center",padding:"20px 0"}}});function d(e){let{children:t,caption:r,imgPosition:i="left",links:a,title:d,...h}=e,p={sm:"column",md:"row"};return"right"===i&&(p={sm:"column",md:"row-reverse"}),(0,n.jsxs)(o.Z,{display:"flex",direction:p,spacing:5,mx:"auto",...h,children:[(0,n.jsx)(l,{children:t}),(0,n.jsxs)(u,{textAlign:i,children:[!!d&&(0,n.jsx)(s.Z,{variant:"subtitle1",children:d}),(0,n.jsx)(s.Z,{variant:"body2",gutterBottom:!0,component:"div",children:r}),!!a&&a.map((e,t)=>(0,n.jsx)(s.Z,{variant:"caption",children:(0,n.jsx)(c.Z,{href:e.url,children:e.text})},"link-".concat(t)))]})]})}},80880:function(e,t,r){"use strict";r.d(t,{Ls:function(){return o},Yo:function(){return s},ZP:function(){return c}});var n=r(57437),i=r(16210),a=r(53527);let o=300,s=(0,i.default)("img")(e=>{let{theme:t,unconstrained:r}=e;return{width:"100%",height:"auto",margin:"auto",objectFit:"cover",objectPosition:"center",borderRadius:r?"0px":"30px",maxHeight:r?"unset":o+"px",[t.breakpoints.down("md")]:{width:"100% !important"}}});function c(e){let{src:t,unconstrained:r=!1,imgProps:i={},...o}=e;return(0,n.jsx)(a.Z,{...o,children:(0,n.jsx)(s,{src:t,unconstrained:r,...i})})}},18311:function(e,t,r){"use strict";r.d(t,{M:function(){return n}});let n=(0,r(16210).default)("img")({width:"100%",height:"auto",objectFit:"cover",objectPosition:"center",borderRadius:"30px",minHeight:"300px"})},8958:function(e,t,r){"use strict";r.d(t,{Z:function(){return j}});var n=r(57437),i=r(30812),a=r(36137),o=r(41530),s=r(46387),c=r(97494),l=r(28163),u=r(7601),d=r(36185),h=r(37937),p=r(43706),f=r(72843),g=r(7237),m=r(71310),A=r(48424),x=r(16210),w=r(94013),R=r(70264);let I=(0,x.default)(w.Z)(e=>{let{}=e;return{whiteSpace:"nowrap",margin:"4px",textTransform:"none"}});function v(e){let{href:t,children:r,...i}=e;return(0,n.jsx)(R.Z,{href:t,passHref:!0,children:(0,n.jsx)(I,{variant:"outlined",size:"small",...i,children:r})})}var L=r(49089);function C(e){let{url:t,text:r,type:i}=e;switch(i){case"github":return(0,n.jsx)(v,{startIcon:(0,n.jsx)(u.Z,{}),color:"githubBlack",href:t,children:r});case"paper":return(0,n.jsx)(v,{startIcon:(0,n.jsx)(d.Z,{}),color:"info",href:t,children:r});case"news":return(0,n.jsx)(v,{startIcon:(0,n.jsx)(h.Z,{}),color:"info",href:t,children:r});case"linkedin":return(0,n.jsx)(v,{startIcon:(0,n.jsx)(p.Z,{}),color:"linkedinBlue",href:t,children:r});case"web":return(0,n.jsx)(v,{startIcon:(0,n.jsx)(f.Z,{}),color:"info",href:t,children:r});case"youtube":return(0,n.jsx)(v,{startIcon:(0,n.jsx)(g.Z,{}),color:"youtubeRed",href:t,children:r});case"instagram":return(0,n.jsx)(v,{startIcon:(0,n.jsx)(m.Z,{}),color:"instagramPink",href:t,children:r});case"appstore":return(0,n.jsx)(v,{startIcon:(0,n.jsx)(L.r2Q,{}),color:"appstoreBlue",href:t,children:r});case"book":return(0,n.jsx)(v,{startIcon:(0,n.jsx)(A.Z,{}),color:"success",href:t,children:r});default:return null}}function j(e){let{skills:t,buttons:r}=e;return(0,n.jsx)(i.Z,{variant:"outlined",sx:{mt:1,borderRadius:"15px"},children:(0,n.jsx)(a.Z,{sx:{p:"16px !important"},children:(0,n.jsxs)(o.Z,{direction:"column",children:[(0,n.jsx)(s.Z,{variant:"overline",children:"Skills"}),(0,n.jsx)(o.Z,{direction:"row",width:"100%",flexWrap:"wrap",children:t.map((e,t)=>(0,n.jsx)(l.Z,{skill:e},"skill-".concat(t)))}),!!r&&!!r.length&&(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(c.Z,{sx:{my:"12px"}}),(0,n.jsx)(o.Z,{direction:"row",flexWrap:"wrap",justifyContent:"center",children:r.map((e,t)=>(0,n.jsx)(C,{...e},"button-".concat(t)))})]})]})})})}},53874:function(e,t,r){"use strict";r.d(t,{Z:function(){return c}});var n=r(57437),i=r(16210),a=r(41530),o=r(46387);let s=(0,i.default)("img")(e=>{let{theme:t}=e;return{height:"50px",[t.breakpoints.down("md")]:{margin:"auto"}}});function c(e){let{title:t,imgSrc:r,...i}=e;return(0,n.jsxs)(a.Z,{direction:"row",alignItems:"flex-end",justifyContent:"space-between",flexWrap:"wrap",mb:2,...i,children:[(0,n.jsx)(o.Z,{variant:"h4",children:t}),(0,n.jsx)(s,{src:r,alt:"Logo"})]})}},28163:function(e,t,r){"use strict";r.d(t,{Z:function(){return h}});var n=r(57437);let i={LANGUAGE:"primary",LIBRARY:"secondary",APPLICATION:"success",CATEGORY:"info",HARDWARE:"warning",PLATFORM:"error",SOFT_SKILL:"default"},a={Robotics:"CATEGORY",EE:"CATEGORY",CS:"CATEGORY",AI:"CATEGORY",AP:"CATEGORY",Athletics:"CATEGORY",Volunteering:"CATEGORY",BME:"CATEGORY",CivE:"CATEGORY","Cloud Computing":"CATEGORY",Art:"CATEGORY",Photography:"CATEGORY",Videography:"CATEGORY",WebDev:"CATEGORY",Hardware:"CATEGORY",CAD:"CATEGORY",Animation:"CATEGORY",Startup:"CATEGORY",Healthcare:"CATEGORY",Engineering:"CATEGORY","3D":"CATEGORY",Research:"CATEGORY","Computer Vision":"CATEGORY","Graph Neural Networks":"CATEGORY","Deep Learning":"CATEGORY","Machine Learning":"CATEGORY","Neural Architecture Search":"CATEGORY",Python:"LANGUAGE",C:"LANGUAGE",HTML:"LANGUAGE",CSS:"LANGUAGE",JavaScript:"LANGUAGE",TypeScript:"LANGUAGE",SQL:"LANGUAGE",Markdown:"LANGUAGE",Mathematica:"LANGUAGE",ROS1:"LIBRARY",Gazebo:"LIBRARY",RViz:"LIBRARY",TensorFlow:"LIBRARY",PyTorch:"LIBRARY",NextJS:"LIBRARY",ReactJS:"LIBRARY",ReduxJS:"LIBRARY",ThreeJS:"LIBRARY",Open3D:"LIBRARY",Trimesh:"LIBRARY","Material UI":"LIBRARY",Django:"LIBRARY",PostgreSQL:"LIBRARY",Stripe:"LIBRARY",Langchain:"LIBRARY",Discourse:"LIBRARY",Docusaurus:"LIBRARY","PyTorch Geometric":"LIBRARY",Formik:"LIBRARY",Yup:"LIBRARY",Jest:"LIBRARY","Unit Testing":"LIBRARY",Soldering:"HARDWARE",Circuits:"HARDWARE",Embedded:"HARDWARE","Embedded Systems":"HARDWARE",Arduino:"HARDWARE",Linux:"PLATFORM",Docker:"PLATFORM",Kubernetes:"PLATFORM",AWS:"PLATFORM",DigitalOcean:"PLATFORM",iOS:"PLATFORM",Unity:"APPLICATION",SolidWorks:"APPLICATION",Maya:"APPLICATION",Blender:"APPLICATION",Git:"APPLICATION","Draw.io":"APPLICATION","NVIDIA CUDA":"APPLICATION",Anaconda:"APPLICATION",Overleaf:"APPLICATION",Figma:"APPLICATION",Jira:"APPLICATION",Leadership:"SOFT_SKILL","Conflict Resolution":"SOFT_SKILL","Public Speaking":"SOFT_SKILL",Networking:"SOFT_SKILL","Social Media":"SOFT_SKILL",Negotiation:"SOFT_SKILL","Technical Writing":"SOFT_SKILL","Agile Software Development":"SOFT_SKILL"};var o=r(16210),s=r(67571),c=r(13735),l=r.n(c),u=r(27648);let d=(0,o.default)(s.Z)(e=>{let{theme:t,hovercolor:r}=e;return{margin:"3px",transition:"all 0.6s ease",":hover":{color:t.palette.common.white,borderColor:"".concat(l()(t,"palette.".concat(r,".light"),null==t?void 0:t.palette.grey[800])," !important"),backgroundColor:"".concat(l()(t,"palette.".concat(r,".light"),null==t?void 0:t.palette.grey[800])," !important")}}});function h(e){let{skill:t,...r}=e,o=l()(a,t,"default"),s=l()(i,o,"default");return(0,n.jsx)(u.default,{href:"/search?skill=".concat(t),passHref:!0,scroll:!1,children:(0,n.jsx)(d,{color:s,label:t,size:"small",variant:"outlined",hovercolor:s,...r})})}}},function(e){e.O(0,[7699,5451,2978,3007,353,619,2971,2117,1744],function(){return e(e.s=69553)}),_N_E=e.O()}]);